{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating estimate of excess services in dollars\n",
    "This step follows Step_A. It loads the stored metric results from different harmonization/mapping algorithms and imputes associated costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "from cw_package.setup_cw_env import *\n",
    "from pylab import *\n",
    "from cw_package import prDF\n",
    "import pickle\n",
    "import re\n",
    "jacks_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for file output at end of this notebook\n",
    "coded_date = '2017_07_12allfeed_woI10'\n",
    "\n",
    "# Per mdsave.com for zipcode 37212, low-ball estimate on 11/11/2016\n",
    "costof_vitd_test =40 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of functions:\n",
    "\n",
    "theoretical_costs() \n",
    "    - this function extrapolates the costs of the tests/services for the numerator and denominator of the metric examined.\n",
    "    \n",
    "     Inputs:\n",
    "        Ref cost table (RVU calculated)\n",
    "        Drug ref cost table (Medicaid data)\n",
    "        Vit D serum testing cost (set at top of this file)\n",
    "        Metric ?dataframes v. Dictionary of dictionaries\n",
    "        Metric identifier (string)\n",
    "        Term ('numerator'/'denominator')\n",
    "        \n",
    "    Use:\n",
    "        This function is employed by the perform_dollar_est() function.\n",
    "        \n",
    "perform_dollar_est()\n",
    "    - This function calculates the theoretical costs for the metrics; intended for single step comprehensive calculation\n",
    "    \n",
    "    Input:\n",
    "        key_list (list of string identifiers for individual CW_metric)\n",
    "        dollar_ref (RVU ref table)\n",
    "        drugdollar_ref (Medicaid drug ref table)\n",
    "        cost of vitD (set at start of this notebook)\n",
    "        phi_DDs (list of tuples of dictionaries of dictionaires for individual GEMs -- ??)\n",
    "        \n",
    "stitch_metricterms()\n",
    "    - function to put all dictionary data for single GEM and single term in one dataframe\n",
    "    \n",
    "compare_outputs_au()\n",
    "    - function to compare output with the annotated-gold-standard \n",
    "    - This IS NOT ACTIVE - early function drafted, but replaced by separate ipython notebook.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theoretical_costs(ref_costs, drugref_costs,costof_vitd1, cw_DDs, metric, term):\n",
    "    cw_DDs2= cw_DDs['{}'.format(metric)]['{}'.format(term)].loc[:,['MRN','ENC_ID','TEST_CODE','TEST_DATE','ICD9_subcode','TEST_DATE_month','CLAIM_DATE_month']]\n",
    "    if metric in ['CW_psyc','CW_narc']:\n",
    "        cw_DDs3 = cw_DDs2.merge(drugref_costs[['old_names_tokenized','Drug Codes', 'NDC', 'Median_NADAC_PerUnit']],\n",
    "                                left_on='TEST_CODE', right_on='Drug Codes',how='left')\n",
    "        cw_DDs3.rename(columns = {'Median_NADAC_PerUnit':'dollar_reimb'},inplace='True')\n",
    "    elif metric in ['CW_vitd']:\n",
    "        # this chunk is needed b/c none of the vitd codes have RVUs associated with them\n",
    "        cw_DDs3 = cw_DDs2.merge(ref_costs[['HCPCS','dollar_reimb']],\n",
    "                                left_on='TEST_CODE', right_on='HCPCS',how='left')\n",
    "        cw_DDs3['vitdcost'] = costof_vitd1\n",
    "        cw_DDs3.rename(columns={'dollar_reimb':'RVU_dollars','vitdcost':'dollar_reimb'},inplace='True')\n",
    "    else:    \n",
    "        cw_DDs3 = cw_DDs2.merge(ref_costs[['HCPCS','dollar_reimb']],left_on='TEST_CODE', right_on='HCPCS',how='left')\n",
    "    cw_DDs3['Term']=term\n",
    "    return cw_DDs3\n",
    "\n",
    "def perform_dollar_est(key_list, dollar_ref,drugdollar_ref,costof_vitd, phi_DDs):\n",
    "    # phi_DDs is a list of tuples of dictionaries of dictionaries, each prepared by different GEM\n",
    "    # dollar_ref is the CPT:$reimbursement reference table\n",
    "    # key_list is the list of CW_metrics\n",
    "    output = {}\n",
    "    for x in phi_DDs:\n",
    "        num = {}\n",
    "        den ={}\n",
    "        for y in key_list:\n",
    "            try:\n",
    "                num[y]=theoretical_costs(dollar_ref, drugdollar_ref,costof_vitd, x[1],y,'numerator')\n",
    "                den[y]=theoretical_costs(dollar_ref, drugdollar_ref,costof_vitd, x[1],y,'denominator')\n",
    "            except:\n",
    "                try:\n",
    "                    den[y]=theoretical_costs(dollar_ref, drugdollar_ref, costof_vitd, x[1],y,'denominator')\n",
    "                except:\n",
    "                    pass\n",
    "        output[x[0]]={'numerator':num,'denominator':den}\n",
    "    return output\n",
    "\n",
    "\n",
    "def stitch_metricterms(dict_dataframes, term_nd):\n",
    "    widget = dict_dataframes\n",
    "    try:\n",
    "        widget_concat = pd.concat([widget['CW_cerv'][term_nd],\n",
    "               widget['CW_card'][term_nd],\n",
    "               widget['CW_vitd'][term_nd],\n",
    "               widget['CW_bph'][term_nd],\n",
    "               widget['CW_lbp'][term_nd],\n",
    "               widget['CW_feed'][term_nd],\n",
    "               widget['CW_psyc'][term_nd],\n",
    "               widget['CW_dexa'][term_nd],\n",
    "               widget['CW_narc'][term_nd],\n",
    "               widget['CW_nonpreop'][term_nd],\n",
    "               widget['CW_catpreop'][term_nd]])\n",
    "    except:\n",
    "        widget_concat = pd.concat([widget['CW_cerv'][term_nd],\n",
    "               widget['CW_card'][term_nd],\n",
    "               widget['CW_vitd'][term_nd],\n",
    "               widget['CW_bph'][term_nd],\n",
    "               widget['CW_lbp'][term_nd],\n",
    "              # widget['CW_feed']['numerator'],\n",
    "               widget['CW_psyc'][term_nd],\n",
    "               widget['CW_dexa'][term_nd],\n",
    "               widget['CW_narc'][term_nd],\n",
    "               widget['CW_nonpreop'][term_nd],\n",
    "               widget['CW_catpreop'][term_nd]])\n",
    "    widget_concat=widget_concat[['ENC_ID','MRN','TEST_CODE','TEST_DATE_a', 'TEST_DATE_month','CLAIM_DATE_month', 'CLAIM_DATE','ADM_DT_a', 'AgeAtTest']]\n",
    "    widget_concat['MRN']=widget_concat['MRN'].apply(lambda x: re.sub('^0{1,2}','',x))\n",
    "    return widget_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevenkeys= ['CW_cerv','CW_card','CW_vitd','CW_bph','CW_lbp','CW_feed','CW_psyc','CW_dexa','CW_narc',\n",
    "             'CW_nonpreop','CW_catpreop']\n",
    "\n",
    "terms = ['numerator','denominator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMMS_dollars = pd.read_csv('./ref/Cost_analy_ref/RVU16A_lastcolumndollars_Jack_use.csv',header=0)\n",
    "\n",
    "# MOD column (NaN: bucketed costs, 26: professional component, TC: technical component, 53: aborted/noncompleted CPT)\n",
    "CMMS_dollars= CMMS_dollars[['HCPCS','MOD','DESCRIPTION','WORK RVU','FACILITY PE RVU','MP RVU', 'FACILITY TOTAL',\n",
    "                            'CONV FACTOR', 'Calc_reimb_GPCIof1']]\n",
    "CMMS_dollars = CMMS_dollars[CMMS_dollars.MOD.isnull()]\n",
    "CMMS_dollars = CMMS_dollars.iloc[:,[0,2,6,8]]\n",
    "CMMS_dollars = CMMS_dollars.rename(columns={'Calc_reimb_GPCIof1':'dollar_reimb'},inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medicaiddrug_dollars = pd.read_csv('./ref/Cost_analy_ref/single_drugcodescost_table.csv')\n",
    "Medicaiddrug_dollars = pd.read_csv('./ref/Cost_analy_ref/single_drugcodescost_table_2017_07_16.csv')\n",
    "Medicaiddrug_dollars = Medicaiddrug_dollars[['old_names_tokenized', 'Drug Codes', 'NDC', 'Median_Per_Unit_Cost', 'Pricing_Unit', \n",
    "                                             'Explanation_Code','As of Date']]\n",
    "Medicaiddrug_dollars.rename(columns = {'Median_Per_Unit_Cost':'Median_NADAC_PerUnit'},inplace='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing pickled results, by GEM, for all CW_metrics\n",
    "These pickled results were created by Step_A.ipynb\n",
    "   \n",
    "   \n",
    ">the \"p-\" prefix stands for \"pickled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_10to10 = pd.read_pickle('./exported/'+coded_date+'/pickled_f_10to10_'+coded_date+'.p')\n",
    "pclaimto9_reimb = pd.read_pickle('./exported/'+coded_date+'/pickled_f_claimto9_reimb_'+coded_date+'.p')\n",
    "pclaimto9_bestMap10 = pd.read_pickle('./exported/'+coded_date+'/pickled_f_claimto9_bestMap10_'+coded_date+'.p')\n",
    "prefto10_bestMap9 = pd.read_pickle('./exported/'+coded_date+'/pickled_f_refto10_bestMap9_'+coded_date+'.p')\n",
    "prefto10_gems = pd.read_pickle('./exported/'+coded_date+'/pickled_f_refto10_gems_'+coded_date+'.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltally = pd.read_pickle('./exported/'+coded_date+'/pickled_tallied_ratios_'+coded_date+'.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code that re-counts total cases in numerator and denominator from monthly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip while no monthly grouping active in code\n",
    "\"\"\"\n",
    "\n",
    "num_claimto9_bestMap10 = pd.read_csv('./exported/'+coded_date+'/claimto9_bestMap10numerator'+coded_date+'.csv')\n",
    "num_claimto9_bestMap10.rename(columns={'Unnamed: 0':'Term'},inplace='True')\n",
    "num_claimto9_bestMap10['Term']='numerator'\n",
    "den_claimto9_bestMap10 = pd.read_csv('./exported/'+coded_date+'/claimto9_bestMap10denominator'+coded_date+'.csv')\n",
    "den_claimto9_bestMap10.rename(columns={'Unnamed: 0':'Term'},inplace='True')\n",
    "den_claimto9_bestMap10['Term']='denominator'\n",
    "\n",
    "# in retrospect on Jan 19 '17, unclear why variables' prefixes are mon_ and smon_\n",
    "mon_claimto9_bestMap10 = pd.concat([num_claimto9_bestMap10, den_claimto9_bestMap10])\n",
    "smon_claimto9_bestMap = mon_claimto9_bestMap10.groupby(['Metric','Term','TEST_DATE_month'])['MRN'].count()\n",
    "smon_claimto9_bestMap.unstack('TEST_DATE_month')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(finaltally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the double dictionary tuples, for each GEM, of numerators and denominators\n",
    "    And then placing them in single list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_p10to10 = ('ten_to_10', p_10to10)\n",
    "dd_pclaimto9_bestMap10 = ('claimto9_bestMap10', pclaimto9_bestMap10)\n",
    "dd_pclaimto9_reimb = ('claimto9_reimb', pclaimto9_reimb)\n",
    "dd_prefto10_gems = ('refto10_gems', prefto10_gems)\n",
    "dd_prefto10_bestMap9 = ('refto10_bestMap9', prefto10_bestMap9)\n",
    "\n",
    "compiled_DDs = [dd_p10to10, dd_pclaimto9_bestMap10, dd_pclaimto9_reimb, dd_prefto10_gems, dd_prefto10_bestMap9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step strips away the CW_feed that are \"na\" b/c no mapping existed for the procedure codes.\n",
    "(This was irrelevant in final version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in compiled_DDs:\n",
    "    try:\n",
    "        if x[1]['CW_feed']['denominator_l']=='na':\n",
    "            del x[1]['CW_feed'] \n",
    "            print('deletion committed')\n",
    "    except:\n",
    "        print('nothing')\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This cell is a testing cell to demonstrate calculation of total VitD dollars at stake, \n",
    "#          by denominator for the claimto9_bestMap10 GEM - stored in compiled_DDs[0][1]\n",
    "theoretical_costs(CMMS_dollars, Medicaiddrug_dollars, costof_vitd_test,compiled_DDs[0][1], 'CW_vitd','denominator').head(3)\n",
    "len(dd_pclaimto9_bestMap10[1]['CW_vitd']['denominator'])*40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the dollar estimation for all GEMs, metrics and terms --> stored in \"single_costdictionary\"\n",
    "then manipulated through the omega dictionary, to the alpha dictionary, then concatenated into the output dataframe.\n",
    "<br>    \n",
    "The \"output\" dataframe is used further down to export it in a spreadsheet for easy visualization and storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_costdictionary = perform_dollar_est(elevenkeys, CMMS_dollars, Medicaiddrug_dollars,costof_vitd_test, compiled_DDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(omega['claimto9_bestMap10']['denominator']['CW_cerv'],Livia.groupby(['term']).sum())\n",
    "omega={}\n",
    "for x,y in single_costdictionary.items():\n",
    "    #print('GEM-key is '+x)\n",
    "    beta={}\n",
    "    for a,b in y.items():\n",
    "        beta[a]=pd.concat({c:pd.concat([d.groupby('Term')['dollar_reimb'].sum()],axis=1) for c,d in b.iteritems()},axis=0)\n",
    "    omega[x]=beta\n",
    "alpha={}\n",
    "for x,y in omega.items():\n",
    "    alpha[x]=pd.concat([y['numerator'],y['denominator']],axis=0)\n",
    "for x,y in alpha.items():\n",
    "    y.rename(columns={'dollar_reimb':'{}'.format(x)},inplace='True')\n",
    "output=pd.concat((y for x,y in alpha.items()),axis=1, join='outer',names=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This creates summary table from pickled final tally that was imported far above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_table =pd.DataFrame([[col1,col2,col3[0],col3[1]] for col1, d in finaltally.items() for col2, col3 in d.items()],\n",
    "                         columns=['GEM type','Metric','Numerator','Denominator'])\n",
    "summ_table.rename(columns={2:'numerator',3:'denominator'},inplace='True')\n",
    "summ_table=summ_table.pivot(index='Metric',columns='GEM type')\n",
    "summ_table= summ_table.stack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./exported/Final Charts')\n",
    "output.fillna(0).to_csv(coded_date+'/Final_composite_cost_estimate_'+coded_date+'.csv')\n",
    "summ_table.to_csv(coded_date+'/Final_composite_counts_'+coded_date+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For inspecting the summary table's composite counts \n",
    "Differs in narc and psyc counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin={}\n",
    "for x,y in single_costdictionary.items():\n",
    "    #print('GEM-key is '+x)\n",
    "    walsh={}\n",
    "    for a,b in y.items():\n",
    "        walsh[a]=pd.concat({c:pd.concat([d.groupby('Term')['MRN'].count()],axis=1) for c,d in b.iteritems()},axis=0)\n",
    "    colin[x]=walsh\n",
    "riverpo={}\n",
    "for x,y in colin.items():\n",
    "    riverpo[x]=pd.concat([y['numerator'],y['denominator']],axis=0)\n",
    "for x,y in riverpo.items():\n",
    "    y.rename(columns={'MRN':'{}'.format(x)},inplace='True')\n",
    "thenile=pd.concat((y for x,y in riverpo.items()),axis=1, join='outer',names=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thenile.fillna(0).to_csv(coded_date+'/forcheckingthe_summtablefigures_'+coded_date+'.csv')\n",
    "print('processing complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
